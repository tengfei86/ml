{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c97f1497b42d357c1929916f8b2f965d766021a3"
   },
   "source": [
    "# Background\n",
    "- As you know, there are features which have high cardinality in this competition.\n",
    "- I've studied and read some discussions, blogs and articles about high cardinality.\n",
    "- In this kernel, I'll experiment to see which encoding works better.\n",
    "- Label encoding, Frequency encoding and Mean encoding will be tested.\n",
    "- Because I'm student, I welcome your feedback on anything of this contents.!\n",
    "- Ok, Let's see!.\n",
    "- To compare, I forked great kernel https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-ga-customer-revenue.\n",
    "- I set the same rrandom number and same parameters for each cases.\n",
    "- I want to recommend you, this kernel. https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study. \n",
    "- This kernel experiments and explains these encodings. Very useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:28:54.366049Z",
     "start_time": "2018-09-25T09:28:53.982745Z"
    },
    "_uuid": "2a14b2ab334a1422479f66606fd38bac624be368"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:08.122157Z",
     "start_time": "2018-09-25T09:28:54.367550Z"
    },
    "_uuid": "b9edcb9cfe5d7c4970dd8e61b90446840f03a803"
   },
   "outputs": [],
   "source": [
    "def load_df(csv_path='./all/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': str}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "6083b8076522ec4adec2fcca4bde8af5f6bd8b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (903653, 55)\n",
      "Loaded test.csv. Shape: (804684, 53)\n",
      "CPU times: user 4min 51s, sys: 21.1 s, total: 5min 12s\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = load_df()\n",
    "df_test = load_df(\"./all/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:08.129814Z",
     "start_time": "2018-09-25T09:29:08.123806Z"
    },
    "_uuid": "6511c695b027e48bbd8590751e903b57a7d9a497"
   },
   "outputs": [],
   "source": [
    "df_train[\"totals_transactionRevenue\"] = df_train[\"totals_transactionRevenue\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:10.074241Z",
     "start_time": "2018-09-25T09:29:08.131328Z"
    },
    "_uuid": "38aca860f4c0eaa79ee4229937edab70590b2825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['socialEngagementType',\n",
       " 'device_browserSize',\n",
       " 'device_browserVersion',\n",
       " 'device_flashVersion',\n",
       " 'device_language',\n",
       " 'device_mobileDeviceBranding',\n",
       " 'device_mobileDeviceInfo',\n",
       " 'device_mobileDeviceMarketingName',\n",
       " 'device_mobileDeviceModel',\n",
       " 'device_mobileInputSelector',\n",
       " 'device_operatingSystemVersion',\n",
       " 'device_screenColors',\n",
       " 'device_screenResolution',\n",
       " 'geoNetwork_cityId',\n",
       " 'geoNetwork_latitude',\n",
       " 'geoNetwork_longitude',\n",
       " 'geoNetwork_networkLocation',\n",
       " 'totals_visits',\n",
       " 'trafficSource_adwordsClickInfo.criteriaParameters']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_cols = [c for c in df_train.columns if df_train[c].nunique(dropna=False)==1 ]\n",
    "const_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:10.431481Z",
     "start_time": "2018-09-25T09:29:10.075821Z"
    },
    "_uuid": "a6dae4ab1a5ba3615d7fbadd9879446a1044aa45"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = const_cols + ['sessionId']\n",
    "\n",
    "df_train = df_train.drop(cols_to_drop + [\"trafficSource_campaignCode\"], axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:10.436270Z",
     "start_time": "2018-09-25T09:29:10.433221Z"
    },
    "_uuid": "f0ad3c32bc4c7f6581ac75b672742e71e66eec13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903653, 34) (804684, 33)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:10.547422Z",
     "start_time": "2018-09-25T09:29:10.437810Z"
    },
    "_uuid": "d99414c34311ddd8accbde02eb4d9550f505651e"
   },
   "outputs": [],
   "source": [
    "# Impute 0 for missing target values\n",
    "df_train[\"totals_transactionRevenue\"].fillna(0, inplace=True)\n",
    "train_y = df_train[\"totals_transactionRevenue\"].values\n",
    "train_id = df_train[\"fullVisitorId\"].values\n",
    "test_id = df_test[\"fullVisitorId\"].values\n",
    "\n",
    "\n",
    "# label encode the categorical variables and convert the numerical variables to float\n",
    "cat_cols = [\"channelGrouping\", \"device_browser\", \n",
    "            \"device_deviceCategory\", \"device_operatingSystem\", \n",
    "            \"geoNetwork_city\", \"geoNetwork_continent\", \n",
    "            \"geoNetwork_country\", \"geoNetwork_metro\",\n",
    "            \"geoNetwork_networkDomain\", \"geoNetwork_region\", \n",
    "            \"geoNetwork_subContinent\", \"trafficSource_adContent\", \n",
    "            \"trafficSource_adwordsClickInfo.adNetworkType\", \n",
    "            \"trafficSource_adwordsClickInfo.gclId\", \n",
    "            \"trafficSource_adwordsClickInfo.page\", \n",
    "            \"trafficSource_adwordsClickInfo.slot\", \"trafficSource_campaign\",\n",
    "            \"trafficSource_keyword\", \"trafficSource_medium\", \n",
    "            \"trafficSource_referralPath\", \"trafficSource_source\",\n",
    "            'trafficSource_adwordsClickInfo.isVideoAd',\n",
    "            'trafficSource_isTrueDirect', 'device_isMobile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:11.846757Z",
     "start_time": "2018-09-25T09:29:10.552253Z"
    },
    "_uuid": "be71c2f7629ae170e57577e8f389e3f2d4a36600"
   },
   "outputs": [],
   "source": [
    "df_train['date'] = df_train['date'].apply(lambda x: (str(x)[:4]) + (str(x)[4:6]) + (str(x)[6:]))\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "051cc70e531d6a7b59d1d66cc29a65522cefb0c4"
   },
   "outputs": [],
   "source": [
    "num_cols = [\"totals_hits\", \"totals_pageviews\", \n",
    "            \"visitNumber\", \"visitStartTime\", \n",
    "            'totals_bounces',  'totals_newVisits']    \n",
    "\n",
    "for col in num_cols:\n",
    "    df_train[col] = df_train[col].astype(float)\n",
    "    df_test[col] = df_test[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:12.058823Z",
     "start_time": "2018-09-25T09:29:11.848305Z"
    },
    "_uuid": "edd8f9e2a8a899d62ec1cb416ed8929b892f769e"
   },
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()\n",
    "\n",
    "df_train = df_train_copy.copy()\n",
    "df_test = df_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:29:12.275588Z",
     "start_time": "2018-09-25T09:29:12.271869Z"
    },
    "_uuid": "4d7762bed9e3caf6a2d6a2a81bdd9391013288d9"
   },
   "outputs": [],
   "source": [
    "train_dates = df_train['date'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72a8873eb15cf003697cd3c5b97b26778b018dfe"
   },
   "source": [
    "# Label-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:12.394295Z",
     "start_time": "2018-09-25T09:29:12.277215Z"
    },
    "_uuid": "d098d19521ed1b4ade2c4e86e49f008655b69472"
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(df_train[col].values.astype('str')) + list(df_test[col].values.astype('str')))\n",
    "    df_train[col] = lbl.transform(list(df_train[col].values.astype('str')))\n",
    "    df_test[col] = lbl.transform(list(df_test[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:12.623907Z",
     "start_time": "2018-09-25T09:31:12.556413Z"
    },
    "_uuid": "0602a6f20204b6269c565a5137aa7207ee79a35b"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:12.740011Z",
     "start_time": "2018-09-25T09:31:12.626703Z"
    },
    "_uuid": "ed74b5bc18de6bbcbb4db4de1683ca98f98b3ad4"
   },
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if col not in num_cols and col not in cat_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:12.846879Z",
     "start_time": "2018-09-25T09:31:12.744677Z"
    },
    "_uuid": "a216914ff7961e5fbc8c455a9e74e3e6deb85134"
   },
   "outputs": [],
   "source": [
    "not_use_cols = ['date', 'fullVisitorId', 'visitId', 'totals_transactionRevenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:12.995131Z",
     "start_time": "2018-09-25T09:31:12.850542Z"
    },
    "_uuid": "fe03664e2d968e5c08479729b735dc9f3029c437"
   },
   "outputs": [],
   "source": [
    "len(cat_cols) + len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:13.100848Z",
     "start_time": "2018-09-25T09:31:12.999462Z"
    },
    "_uuid": "88e626777431366daae0d5c42d1ae483f4303b8d"
   },
   "outputs": [],
   "source": [
    "len(not_use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:30.290397Z",
     "start_time": "2018-09-25T09:31:13.105649Z"
    },
    "_uuid": "14f7206db3e649874350e78d43039544d4eb7965"
   },
   "outputs": [],
   "source": [
    "# Split the train dataset into development and valid based on time \n",
    "dev_df = df_train[df_train['date']<=pd.to_datetime(\"2017-5-31\")]\n",
    "val_df = df_train[df_train['date']>pd.to_datetime(\"2017-5-31\")]\n",
    "dev_y = np.log1p(dev_df[\"totals_transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals_transactionRevenue\"].values)\n",
    "\n",
    "use_cols = [col for col in df_train.columns if col not in not_use_cols]\n",
    "\n",
    "dev_X = dev_df[use_cols] \n",
    "val_X = val_df[use_cols] \n",
    "test_X = df_test[use_cols] \n",
    "\n",
    "# custom function to run light gbm model\n",
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\", \n",
    "        \"num_leaves\" : 30,\n",
    "        \"min_child_samples\" : 100,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 1989,\n",
    "        \"verbosity\" : -1,\n",
    "        'seed': 1989\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    model = lgb.train(params, lgtrain, 10000, valid_sets=[lgtrain, lgval], early_stopping_rounds=500, verbose_eval=100)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model = run_lgb(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04dbf31865451f5f6b072e5740e7352e8630a960"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\n",
    "sub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "sub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "sub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\n",
    "sub_df.to_csv(\"Label_encoding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ba2fa335a5a997b38395d15f70702f77629d94c"
   },
   "source": [
    "# Frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_copy.copy()\n",
    "df_test = df_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:31:30.294024Z",
     "start_time": "2018-09-25T09:31:30.291803Z"
    },
    "_uuid": "5b16ed07c085827ff4cf92d6ea6448f202e458a0"
   },
   "outputs": [],
   "source": [
    "def frequency_encoding(frame, col):\n",
    "    freq_encoding = frame.groupby([col]).size()/frame.shape[0] \n",
    "    freq_encoding = freq_encoding.reset_index().rename(columns={0:'{}_Frequency'.format(col)})\n",
    "    return frame.merge(freq_encoding, on=col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:32:16.041986Z",
     "start_time": "2018-09-25T09:31:30.749287Z"
    },
    "_uuid": "a2d34b6d53011ed1d68388866cff1e39d34ddf49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      "channelGrouping              8 non-null object\n",
      "channelGrouping_Frequency    8 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 208.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 1/24 [00:10<04:12, 10.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129 entries, 0 to 128\n",
      "Data columns (total 2 columns):\n",
      "device_browser              129 non-null object\n",
      "device_browser_Frequency    129 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 2/24 [00:22<04:02, 11.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      "device_deviceCategory              3 non-null object\n",
      "device_deviceCategory_Frequency    3 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 3/24 [00:34<03:58, 11.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 2 columns):\n",
      "device_operatingSystem              24 non-null object\n",
      "device_operatingSystem_Frequency    24 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 464.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 4/24 [00:45<03:47, 11.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 956 entries, 0 to 955\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_city              956 non-null object\n",
      "geoNetwork_city_Frequency    956 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 15.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 5/24 [00:57<03:39, 11.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_continent              6 non-null object\n",
      "geoNetwork_continent_Frequency    6 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 6/24 [01:09<03:28, 11.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228 entries, 0 to 227\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_country              228 non-null object\n",
      "geoNetwork_country_Frequency    228 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 7/24 [01:20<03:16, 11.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_metro              123 non-null object\n",
      "geoNetwork_metro_Frequency    123 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 8/24 [01:32<03:05, 11.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41982 entries, 0 to 41981\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_networkDomain              41982 non-null object\n",
      "geoNetwork_networkDomain_Frequency    41982 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 656.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 9/24 [01:45<02:55, 11.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 483 entries, 0 to 482\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_region              483 non-null object\n",
      "geoNetwork_region_Frequency    483 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 7.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 10/24 [01:56<02:43, 11.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 2 columns):\n",
      "geoNetwork_subContinent              23 non-null object\n",
      "geoNetwork_subContinent_Frequency    23 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 11/24 [02:08<02:32, 11.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76 entries, 0 to 75\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_adContent              76 non-null object\n",
      "trafficSource_adContent_Frequency    76 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 12/24 [02:19<02:19, 11.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_adwordsClickInfo.adNetworkType              3 non-null object\n",
      "trafficSource_adwordsClickInfo.adNetworkType_Frequency    3 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 13/24 [02:30<02:07, 11.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59008 entries, 0 to 59007\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_adwordsClickInfo.gclId              59008 non-null object\n",
      "trafficSource_adwordsClickInfo.gclId_Frequency    59008 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 922.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 14/24 [02:42<01:56, 11.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_adwordsClickInfo.page              11 non-null object\n",
      "trafficSource_adwordsClickInfo.page_Frequency    11 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▎   | 15/24 [02:53<01:44, 11.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_adwordsClickInfo.slot              3 non-null object\n",
      "trafficSource_adwordsClickInfo.slot_Frequency    3 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 16/24 [03:04<01:32, 11.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_campaign              35 non-null object\n",
      "trafficSource_campaign_Frequency    35 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 640.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 17/24 [03:16<01:20, 11.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5392 entries, 0 to 5391\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_keyword              5392 non-null object\n",
      "trafficSource_keyword_Frequency    5392 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 84.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 18/24 [03:27<01:09, 11.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_medium              7 non-null object\n",
      "trafficSource_medium_Frequency    7 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▉  | 19/24 [03:39<00:57, 11.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3196 entries, 0 to 3195\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_referralPath              3196 non-null object\n",
      "trafficSource_referralPath_Frequency    3196 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 50.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 20/24 [03:51<00:46, 11.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_source              500 non-null object\n",
      "trafficSource_source_Frequency    500 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 21/24 [04:02<00:34, 11.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      "trafficSource_adwordsClickInfo.isVideoAd              1 non-null bool\n",
      "trafficSource_adwordsClickInfo.isVideoAd_Frequency    1 non-null float64\n",
      "dtypes: bool(1), float64(1)\n",
      "memory usage: 89.0 bytes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and bool columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-73619a959727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequency_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d904729ea492>\u001b[0m in \u001b[0;36mfrequency_encoding\u001b[0;34m(frame, col)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfreq_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_encoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'{}_Frequency'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfreq_encoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   6377\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6378\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6379\u001b[0;31m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[1;32m   6380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and bool columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "len_train = df_train.shape[0]\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "for col in tqdm(['trafficSource_isTrueDirect', 'device_isMobile']):\n",
    "    df_all = frequency_encoding(df_all, col)\n",
    "\n",
    "df_train = df_all[:len_train]\n",
    "df_test = df_all[len_train:]\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:32:34.157774Z",
     "start_time": "2018-09-25T09:32:16.043763Z"
    },
    "_uuid": "3073df7a975ae894cd94c950ee408ab9a97363ed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(cat_cols, axis=1, inplace=True)\n",
    "df_test.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "freq_cat_cols = ['{}_Frequency'.format(col) for col in cat_cols]\n",
    "\n",
    "# Split the train dataset into development and valid based on time \n",
    "dev_df = df_train[train_dates<=pd.to_datetime(\"2017-5-31\")]\n",
    "val_df = df_train[train_dates>pd.to_datetime(\"2017-5-31\")]\n",
    "\n",
    "dev_y = np.log1p(dev_df[\"totals_transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals_transactionRevenue\"].values)\n",
    "\n",
    "use_cols = [col for col in df_train.columns if col not in not_use_cols]\n",
    "\n",
    "dev_X = dev_df[use_cols] \n",
    "val_X = val_df[use_cols] \n",
    "test_X = df_test[use_cols]  \n",
    "\n",
    "# Training the model #\n",
    "pred_test, model = run_lgb(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8b6789e0a7032a8f1eeedd1501d7ce5ad971b325"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\n",
    "sub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "sub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "sub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\n",
    "sub_df.to_csv(\"Freq_encoding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e696a170209add199a33a00393755149d105c07"
   },
   "source": [
    "# Mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:32:34.161554Z",
     "start_time": "2018-09-25T09:32:34.159270Z"
    },
    "_uuid": "82252e8a8944a413b229276056bb48db49184fb7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:32:34.246307Z",
     "start_time": "2018-09-25T09:32:34.162684Z"
    },
    "_uuid": "c6af63cde8168c4c83cbca90ff550c0873a8e01e"
   },
   "outputs": [],
   "source": [
    "def mean_k_fold_encoding(col, alpha):\n",
    "    target_name = 'totals_transactionRevenue'\n",
    "    target_mean_global = df_train[target_name].mean()\n",
    "    \n",
    "    nrows_cat = df_train.groupby(col)[target_name].count()\n",
    "    target_means_cats = df_train.groupby(col)[target_name].mean()\n",
    "    target_means_cats_adj = (target_means_cats*nrows_cat + \n",
    "                             target_mean_global*alpha)/(nrows_cat+alpha)\n",
    "    # Mapping means to test data\n",
    "    encoded_col_test = df_test[col].map(target_means_cats_adj)\n",
    "    \n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1989)\n",
    "    parts = []\n",
    "    for trn_inx, val_idx in kfold.split(df_train):\n",
    "        df_for_estimation, df_estimated = df_train.iloc[trn_inx], df_train.iloc[val_idx]\n",
    "        nrows_cat = df_for_estimation.groupby(col)[target_name].count()\n",
    "        target_means_cats = df_for_estimation.groupby(col)[target_name].mean()\n",
    "\n",
    "        target_means_cats_adj = (target_means_cats * nrows_cat + \n",
    "                                target_mean_global * alpha) / (nrows_cat + alpha)\n",
    "\n",
    "        encoded_col_train_part = df_estimated[col].map(target_means_cats_adj)\n",
    "        parts.append(encoded_col_train_part)\n",
    "        \n",
    "    encoded_col_train = pd.concat(parts, axis=0)\n",
    "    encoded_col_train.fillna(target_mean_global, inplace=True)\n",
    "    encoded_col_train.sort_index(inplace=True)\n",
    "    \n",
    "    return encoded_col_train, encoded_col_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:32:34.698010Z",
     "start_time": "2018-09-25T09:32:34.248095Z"
    },
    "_uuid": "52b070dfcf0931cd92407455ed6e678cc6a415e7"
   },
   "outputs": [],
   "source": [
    "df_train = df_train_copy.copy()\n",
    "df_test = df_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:33:14.399588Z",
     "start_time": "2018-09-25T09:32:34.699312Z"
    },
    "_uuid": "fbfbce90c253f033d6a389fb68b302929799a0de"
   },
   "outputs": [],
   "source": [
    "for col in tqdm(cat_cols):\n",
    "    temp_encoded_tr, temp_encoded_te = mean_k_fold_encoding(col, 5)\n",
    "    new_feat_name = 'mean_k_fold_{}'.format(col)\n",
    "    df_train[new_feat_name] = temp_encoded_tr.values\n",
    "    df_test[new_feat_name] = temp_encoded_te.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:33:29.906968Z",
     "start_time": "2018-09-25T09:33:14.400826Z"
    },
    "_uuid": "0aad2ca6813c67501afd1d63569e2b934ec1a79c"
   },
   "outputs": [],
   "source": [
    "df_train.drop(cat_cols, axis=1, inplace=True)\n",
    "df_test.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "mean_cat_cols = ['mean_k_fold_{}'.format(col) for col in cat_cols]\n",
    "\n",
    "# Split the train dataset into development and valid based on time \n",
    "dev_df = df_train[train_dates<=pd.to_datetime(\"2017-5-31\")]\n",
    "val_df = df_train[train_dates>pd.to_datetime(\"2017-5-31\")]\n",
    "\n",
    "dev_y = np.log1p(dev_df[\"totals_transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals_transactionRevenue\"].values)\n",
    "\n",
    "use_cols = [col for col in df_train.columns if col not in not_use_cols]\n",
    "\n",
    "dev_X = dev_df[use_cols] \n",
    "val_X = val_df[use_cols] \n",
    "test_X = df_test[use_cols] \n",
    "\n",
    "# Training the model #\n",
    "pred_test, model = run_lgb(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d92c53cd8033e991b0f342dac79e522a6a50376"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\n",
    "sub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "sub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "sub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\n",
    "sub_df.to_csv(\"mean_encoding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1fc370c75d3e2a3411e2fb7c0415dedfe73bbf01"
   },
   "source": [
    "# Label + Frequency + Mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:35:14.049651Z",
     "start_time": "2018-09-25T09:33:29.908345Z"
    },
    "_uuid": "657ba4ce47c96595c05b0ccf621f36d67bc0af96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 1/24 [00:10<04:01, 10.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 2/24 [00:21<03:55, 10.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▎        | 3/24 [00:33<03:51, 11.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 4/24 [00:44<03:43, 11.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 5/24 [00:56<03:36, 11.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 6/24 [01:08<03:26, 11.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 7/24 [01:21<03:17, 11.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 8/24 [01:33<03:06, 11.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 9/24 [01:45<02:55, 11.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 10/24 [01:57<02:44, 11.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 11/24 [02:09<02:33, 11.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 12/24 [02:21<02:21, 11.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 13/24 [02:33<02:09, 11.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 14/24 [02:45<01:58, 11.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 15/24 [02:57<01:46, 11.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 16/24 [03:09<01:34, 11.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 17/24 [03:21<01:23, 11.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 18/24 [03:33<01:11, 11.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 19/24 [03:45<00:59, 11.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 20/24 [03:58<00:47, 11.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 21/24 [04:10<00:35, 11.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 22/24 [04:21<00:23, 11.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 23/24 [04:33<00:11, 11.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 24/24 [04:45<00:00, 11.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903653, 58) (804684, 58)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train_copy.copy()\n",
    "df_test = df_test_copy.copy()\n",
    "for col in cat_cols:\n",
    "    df_train[col] = df_train[col].astype(str)\n",
    "    df_test[col] = df_test[col].astype(str)\n",
    "len_train = df_train.shape[0]\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "for col in tqdm(['']):\n",
    "    df_all = frequency_encoding(df_all, col)\n",
    "\n",
    "df_train = df_all[:len_train]\n",
    "df_test = df_all[len_train:]\n",
    "\n",
    "print(df_train.shape, df_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 1/24 [00:06<02:33,  6.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 2/24 [00:14<02:38,  7.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▎        | 3/24 [00:21<02:33,  7.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 4/24 [00:30<02:30,  7.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 5/24 [00:39<02:29,  7.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 6/24 [00:48<02:24,  8.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 7/24 [00:56<02:17,  8.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 8/24 [01:05<02:10,  8.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 9/24 [01:14<02:04,  8.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 10/24 [01:23<01:57,  8.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 11/24 [01:32<01:48,  8.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 12/24 [01:39<01:39,  8.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 13/24 [01:47<01:30,  8.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 14/24 [01:54<01:22,  8.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 15/24 [02:02<01:13,  8.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 16/24 [02:09<01:04,  8.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 17/24 [02:17<00:56,  8.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 18/24 [02:25<00:48,  8.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 19/24 [02:34<00:40,  8.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 20/24 [02:42<00:32,  8.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 21/24 [02:51<00:24,  8.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 22/24 [02:59<00:16,  8.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 23/24 [03:06<00:08,  8.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 24/24 [03:14<00:00,  8.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cat_cols):\n",
    "    temp_encoded_tr, temp_encoded_te = mean_k_fold_encoding(col, 5)\n",
    "    new_feat_name = 'mean_k_fold_{}'.format(col)\n",
    "    df_train[new_feat_name] = temp_encoded_tr.values\n",
    "    df_test[new_feat_name] = temp_encoded_te.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['a'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:37:18.429690Z",
     "start_time": "2018-09-25T09:35:14.050824Z"
    },
    "_uuid": "5bab79056d14d622a68035a2363414d82a737d80"
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(df_train[col].values.astype('str')) + list(df_test[col].values.astype('str')))\n",
    "    df_train[col] = lbl.transform(list(df_train[col].values.astype('str')))\n",
    "    df_test[col] = lbl.transform(list(df_test[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:37:18.433008Z",
     "start_time": "2018-09-25T09:37:18.431015Z"
    },
    "_uuid": "71d67008c137c71b87ed878bee2a0a03fdf266a3"
   },
   "outputs": [],
   "source": [
    "freq_cat_cols = ['{}_Frequency'.format(col) for col in cat_cols]\n",
    "mean_cat_cols = ['mean_k_fold_{}'.format(col) for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T09:37:47.844444Z",
     "start_time": "2018-09-25T09:37:18.434225Z"
    },
    "_uuid": "e9947146f2dfc7ab7333c1c9baeb216f4a4ff9af"
   },
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)\n",
    "\n",
    "# Split the train dataset into development and valid based on time \n",
    "dev_df = df_train[train_dates<=pd.to_datetime(\"2017-5-31\")]\n",
    "val_df = df_train[train_dates>pd.to_datetime(\"2017-5-31\")]\n",
    "dev_y = np.log1p(dev_df[\"totals_transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals_transactionRevenue\"].values)\n",
    "\n",
    "use_cols = [col for col in df_train.columns if col not in not_use_cols]\n",
    "\n",
    "dev_X = dev_df[use_cols] \n",
    "val_X = val_df[use_cols] \n",
    "test_X = df_test[use_cols]  \n",
    "\n",
    "# Training the model #\n",
    "pred_test, model = run_lgb(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0fe4e1ecf35d001ab9e231f9e151326e68b4d5f"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\n",
    "sub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "sub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "sub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\n",
    "sub_df.to_csv(\"all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71e60a383949756963850b929d674129813728ce"
   },
   "source": [
    "# Result\n",
    "| Encoding  | Training RMSE  | VALID RMSE  |  RMSE(Tr) / RMSE(vld)  | LB \n",
    "|---|---|---|---|---|\n",
    "| Label encoding |  1.52503  | 1.69546  |  1.111755 |  1.4470\n",
    "|  Frequency encoding | 1.52039  | 1.69291 | 1.113471 | 1.4545\n",
    "|  Mean encoding |  1.52247 | 1.6955  | 1.113651  |  1.4448\n",
    "|Label + Fre + Mean (All) | 1.51965 | 1.69179 | 1.1132761 |  1.4417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3c46174eda46ba2176f597ddcc1d323ce9d8636"
   },
   "source": [
    "- Traning RMSE: All  < Freq < Mean < Label\n",
    "- Valid RMSE: All < Freq < Label < Mean\n",
    "- Tr/vld ratio: Label < All < Freq < Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0dda30390eb96bd6484ac400bdb391bb0b43a6c"
   },
   "source": [
    "- Freq, Mean encoding tend to overfit to training set.\n",
    "- But LB of Mean encoding is lower than LB of Freq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b8b9154b87812f061cb58a653e14c4c20223a47"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd66f8de4ca14ef6669e2fc0111cab14a3f0e0fe"
   },
   "source": [
    "- Of course, it's not easy to say the all(Label + Fre + Mean) is the best choice.\n",
    "- But, adding other encoding performs better than only using label encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2251b9a4db64a05fc57e798ea03b45653c40eb74"
   },
   "source": [
    "# More\n",
    "- I know, this experiment is so simple. The result could be changed depending on hyper-parameters and algoritm.\n",
    "- But, I think adding various encoding give us better performance than using only one encoding strategy because applying various approachs (like ensemble)  commoly shows good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6938751facc768f5aefdecb088d5c5c274407cb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4e76f9ff601260a440b8809fc1dc5a65a1dfc60"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
